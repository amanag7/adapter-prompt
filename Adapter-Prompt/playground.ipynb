{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78535c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/cs21mtech11006/adapter-prompt/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from transformers import AdamW, WEIGHTS_NAME, get_linear_schedule_with_warmup\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from fp16 import FP16_Module, FP16_Optimizer\n",
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "from collections import OrderedDict\n",
    "from utils.utils import *\n",
    "from utils.settings import args, TASK_DICT, init_logging, MODEL_CONFIG, MODEL_CLASS, SPECIAL_TOKENS, CONFIG_CLASS\n",
    "from utils.settings import TOKENIZER, SPECIAL_TOKEN_IDS, FILL_VAL, SAVE_NAME, FINAL_SAVE_NAME, TOKENS_WEIGHT, CONFIG_NAME\n",
    "from scheduler import AnnealingLR\n",
    "from regularizers import REG_TYPES, REG_TYPE_KEYS, Weight_Regularized_AdamW, Weight_Regularized_SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers.adapters import ConfigUnion, AdapterConfig, PrefixTuningConfig\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bbe9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'dummy',\n",
       " 'paragraphs': [{'context': 'a stirring , funny and finally transporting re - imagining of beauty and the beast and 1930 s horror films',\n",
       "   'qas': [{'id': '285b88e29d9911e984570c9d92873668',\n",
       "     'answers': [{'answer_start': None, 'text': 'positive'}],\n",
       "     'question': 'is this review negative or positive ?',\n",
       "     'is_impossible': False}]}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"../../data\"\n",
    "sst = { \"train\":os.path.join(data_dir,\"sst_to_squad-train-v2.0.json\"),\n",
    "           \"eval\":os.path.join(data_dir,\"sst_to_squad-dev-v2.0.json\"),\n",
    "           \"test\":os.path.join(data_dir,\"sst_to_squad-test-v2.0.json\"),\n",
    "      }\n",
    "\n",
    "import pandas as pd\n",
    "sst_train = pd.read_json(sst[\"train\"])\n",
    "\n",
    "sst_train[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6c9233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 16:53:19,161 - 0:19:59 - 0.0s - INFO - __main__ - args = Series([], dtype: object)\n"
     ]
    }
   ],
   "source": [
    "if not args.debug:\n",
    "    logging.getLogger(\"pytorch_transformers\").setLevel(logging.WARNING)\n",
    "    logging.getLogger(\"pytorch_transformers.tokenization_utils\").setLevel(logging.CRITICAL)\n",
    "\n",
    "make_dir(args.model_dir_root)\n",
    "\n",
    "init_logging(os.path.join(args.model_dir_root, 'log_train.txt'))\n",
    "logger.info('args = {}'.format(str(args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL_CLASS.from_pretrained(args.model_name.cuda())\n",
    "model.resize_token_embeddings(len(TOKENIZER))\n",
    "adapter_name = args.tasks[task_id].replace(\".\", \"_\")\n",
    "adapter_config = ConfigUnion(\n",
    "                    AdapterConfig(mh_adapter=True, output_adapter=False, reduction_factor=3, non_linearity=\"relu\"),\n",
    "#                             AdapterConfig(mh_adapter=False, output_adapter=True, reduction_factor=8, non_linearity=\"relu\"),\n",
    "                    AdapterConfig(mh_adapter=False, output_adapter=True, reduction_factor=2, non_linearity=\"relu\")\n",
    "                )\n",
    "#         adapter_config =  ConfigUnion(PrefixTuningConfig(bottleneck_size=800), ParallelConfig(),)\n",
    "model.add_adapter(adapter_name, config=adapter_config)\n",
    "model.set_active_adapters(adapter_name)\n",
    "model = model.to(args.device_ids[0])\n",
    "model.train_adapter(adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee845d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cea881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
