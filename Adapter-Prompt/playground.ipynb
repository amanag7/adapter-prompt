{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78535c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/2021/cs21mtech11006/anaconda3/envs/lamol/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/student/2021/cs21mtech11006/adapter-prompt/Adapter-Prompt/utils/settings.py:35: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  args = pd.Series()\n",
      "No available GPUs!\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "No CPU mode available!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/student/2021/cs21mtech11006/adapter-prompt/Adapter-Prompt/playground.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.159/home/student/2021/cs21mtech11006/adapter-prompt/Adapter-Prompt/playground.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mparallel\u001b[39;00m \u001b[39mimport\u001b[39;00m DataParallelModel, DataParallelCriterion\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.159/home/student/2021/cs21mtech11006/adapter-prompt/Adapter-Prompt/playground.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedDict\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.159/home/student/2021/cs21mtech11006/adapter-prompt/Adapter-Prompt/playground.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.159/home/student/2021/cs21mtech11006/adapter-prompt/Adapter-Prompt/playground.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msettings\u001b[39;00m \u001b[39mimport\u001b[39;00m args, TASK_DICT, init_logging, MODEL_CONFIG, MODEL_CLASS, SPECIAL_TOKENS, CONFIG_CLASS\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.50.159/home/student/2021/cs21mtech11006/adapter-prompt/Adapter-Prompt/playground.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msettings\u001b[39;00m \u001b[39mimport\u001b[39;00m TOKENIZER, SPECIAL_TOKEN_IDS, FILL_VAL, SAVE_NAME, FINAL_SAVE_NAME, TOKENS_WEIGHT, CONFIG_NAME\n",
      "File \u001b[0;32m~/adapter-prompt/Adapter-Prompt/utils/utils.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msettings\u001b[39;00m \u001b[39mimport\u001b[39;00m args, TASK_DICT, SPECIAL_TOKENS, SPECIAL_TOKEN_IDS, FILL_VAL\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msettings\u001b[39;00m \u001b[39mimport\u001b[39;00m TOKENIZER, LEN_FACTOR, DATA_ATTRS, MEMORY_FACTOR, MODEL_CONFIG, MODEL_CLASS\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mquadprog\u001b[39;00m\n",
      "File \u001b[0;32m~/adapter-prompt/Adapter-Prompt/utils/settings.py:142\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m root_logger\u001b[39m.\u001b[39mhandlers:\n\u001b[1;32m    139\u001b[0m         handler\u001b[39m.\u001b[39maddFilter(TimeFilter())\n\u001b[0;32m--> 142\u001b[0m args, MODEL_CONFIG, MODEL_CLASS, TOKENIZER, CONFIG_CLASS, SPECIAL_TOKEN_IDS, SPECIAL_TOKENS, DATA_ATTRS, TOKENS_WEIGHT \u001b[39m=\u001b[39m parse_args()\n\u001b[1;32m    144\u001b[0m TASK_DICT \u001b[39m=\u001b[39m {\n\u001b[1;32m    145\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39msquad1\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m    146\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m:os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(args\u001b[39m.\u001b[39mdata_dir,\u001b[39m\"\u001b[39m\u001b[39msquad-train-v1.1.json\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     },\n\u001b[1;32m    241\u001b[0m }\n",
      "File \u001b[0;32m~/adapter-prompt/Adapter-Prompt/utils/settings.py:62\u001b[0m, in \u001b[0;36mparse_args\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args\u001b[39m.\u001b[39mdevice_ids) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     61\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m'\u001b[39m\u001b[39mNo available GPUs!\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo CPU mode available!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args\u001b[39m.\u001b[39mdevice_ids) \u001b[39m<\u001b[39m args\u001b[39m.\u001b[39mn_gpus:\n\u001b[1;32m     65\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\u001b[39m'\u001b[39m\u001b[39mAvailable number of GPU = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m < n_gpus = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(args\u001b[39m.\u001b[39mdevice_ids), args\u001b[39m.\u001b[39mn_gpus))\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: No CPU mode available!"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from transformers import AdamW, WEIGHTS_NAME, get_linear_schedule_with_warmup\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from fp16 import FP16_Module, FP16_Optimizer\n",
    "from parallel import DataParallelModel, DataParallelCriterion\n",
    "from collections import OrderedDict\n",
    "from utils.utils import *\n",
    "from utils.settings import args, TASK_DICT, init_logging, MODEL_CONFIG, MODEL_CLASS, SPECIAL_TOKENS, CONFIG_CLASS\n",
    "from utils.settings import TOKENIZER, SPECIAL_TOKEN_IDS, FILL_VAL, SAVE_NAME, FINAL_SAVE_NAME, TOKENS_WEIGHT, CONFIG_NAME\n",
    "from scheduler import AnnealingLR\n",
    "from regularizers import REG_TYPES, REG_TYPE_KEYS, Weight_Regularized_AdamW, Weight_Regularized_SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers.adapters import ConfigUnion, AdapterConfig, PrefixTuningConfig\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bbe9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'dummy',\n",
       " 'paragraphs': [{'context': 'a stirring , funny and finally transporting re - imagining of beauty and the beast and 1930 s horror films',\n",
       "   'qas': [{'id': '285b88e29d9911e984570c9d92873668',\n",
       "     'answers': [{'answer_start': None, 'text': 'positive'}],\n",
       "     'question': 'is this review negative or positive ?',\n",
       "     'is_impossible': False}]}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"../../data\"\n",
    "sst = { \"train\":os.path.join(data_dir,\"sst_to_squad-train-v2.0.json\"),\n",
    "           \"eval\":os.path.join(data_dir,\"sst_to_squad-dev-v2.0.json\"),\n",
    "           \"test\":os.path.join(data_dir,\"sst_to_squad-test-v2.0.json\"),\n",
    "      }\n",
    "\n",
    "import pandas as pd\n",
    "sst_train = pd.read_json(sst[\"train\"])\n",
    "\n",
    "sst_train[\"data\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc6c9233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-12 16:53:19,161 - 0:19:59 - 0.0s - INFO - __main__ - args = Series([], dtype: object)\n"
     ]
    }
   ],
   "source": [
    "if not args.debug:\n",
    "    logging.getLogger(\"pytorch_transformers\").setLevel(logging.WARNING)\n",
    "    logging.getLogger(\"pytorch_transformers.tokenization_utils\").setLevel(logging.CRITICAL)\n",
    "\n",
    "make_dir(args.model_dir_root)\n",
    "\n",
    "init_logging(os.path.join(args.model_dir_root, 'log_train.txt'))\n",
    "logger.info('args = {}'.format(str(args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODEL_CLASS.from_pretrained(args.model_name.cuda())\n",
    "model.resize_token_embeddings(len(TOKENIZER))\n",
    "adapter_name = args.tasks[task_id].replace(\".\", \"_\")\n",
    "adapter_config = ConfigUnion(\n",
    "                    AdapterConfig(mh_adapter=True, output_adapter=False, reduction_factor=3, non_linearity=\"relu\"),\n",
    "#                             AdapterConfig(mh_adapter=False, output_adapter=True, reduction_factor=8, non_linearity=\"relu\"),\n",
    "                    AdapterConfig(mh_adapter=False, output_adapter=True, reduction_factor=2, non_linearity=\"relu\")\n",
    "                )\n",
    "#         adapter_config =  ConfigUnion(PrefixTuningConfig(bottleneck_size=800), ParallelConfig(),)\n",
    "model.add_adapter(adapter_name, config=adapter_config)\n",
    "model.set_active_adapters(adapter_name)\n",
    "model = model.to(args.device_ids[0])\n",
    "model.train_adapter(adapter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee845d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cea881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
